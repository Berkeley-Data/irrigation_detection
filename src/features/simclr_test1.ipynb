{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from tensorflow.keras.applications import ResNet50, ResNet101V2, Xception, InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from augmentation.gaussian_filter import GaussianBlur\n",
    "# from utils import *\n",
    "# import helpers\n",
    "# import losses\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow Version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Using TensorFlow Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "# BASE_PATH = './BigEarthData'\n",
    "# OUTPUT_PATH = os.path.join(BASE_PATH, 'models')\n",
    "# TFR_PATH = os.path.join(BASE_PATH, 'tfrecords')\n",
    "\n",
    "\n",
    "BASE_PATH = '/workspace/app'\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, 'src/features/tmp/')\n",
    "TFR_PATH = os.path.join(BASE_PATH, 'data/processed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/app/src/features/tmp/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/app/data/processed'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(v1, v2):\n",
    "    k_size = int(v1.shape[1] * 0.1)  # kernel size is set to be 10% of the image height/width\n",
    "    gaussian_ope = GaussianBlur(kernel_size=k_size, min=0.1, max=2.0)\n",
    "    [v1, ] = tf.py_function(gaussian_ope, [v1], [tf.float32])\n",
    "    [v2, ] = tf.py_function(gaussian_ope, [v2], [tf.float32])\n",
    "    return v1, v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "def gaussian_filter(v1, v2):\n",
    "    k_size = int(v1.shape[1] * 0.1)  # kernel size is set to be 10% of the image height/width\n",
    "    gaussian_ope = GaussianBlur(kernel_size=k_size, min=0.1, max=2.0)\n",
    "    [v1, ] = tf.py_function(gaussian_ope, [v1], [tf.float32])\n",
    "    [v2, ] = tf.py_function(gaussian_ope, [v2], [tf.float32])\n",
    "    return v1, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def get_batched_dataset(filenames, batch_size, augment=False):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames, shuffle=True)\n",
    "    print(f'Filenames: {filenames}')\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=2, num_parallel_calls=1)\n",
    "    dataset = dataset.shuffle(buffer_size=2048)\n",
    "    #.repeat()\n",
    "    \n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=10)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)  # drop_remainder will be needed on TPU\n",
    "    dataset = dataset.prefetch(5)  #\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting a dataset generator for our training data. \n",
    "# The flags affect which tfrecords files to use and how to normalize each.\n",
    "def get_training_dataset(training_filenames, batch_size):\n",
    "#     return get_batched_dataset(training_filenames, batch_size, simclr=True, ca=ca_flag)\n",
    "    return get_batched_dataset(training_filenames, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_simclr_model(imported_model, hidden_1, hidden_2, hidden_3):\n",
    "    '''\n",
    "    This function is used to actually create the neural encoder and projection head. The\n",
    "    neural encoder is basically on of ResNet50, ResNet101V2, Xception or InceptionV3 (or any other)\n",
    "    We train 10 channels of the satellite data. The projection head dimensions should be specified as inputs.\n",
    "\n",
    "    imported_model: tensorflow.keras.applications model - ResNet101V2 is typically used\n",
    "    hidden_1: integer - dimension of first layer of the projection head\n",
    "    hidden_2: integer - dimension of second layer of the projection head\n",
    "    hidden_3: integer - output dimension - vector used in the contrastive loss function\n",
    "    '''\n",
    "\n",
    "    # Load in a Keras Model for our neural encoder and set to trainable\n",
    "    base_model = imported_model(include_top=False, weights=None, input_shape=[120,120, 10])\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Input dimensions are fixed to big earth net image dimensions.\n",
    "    inputs = Input((120,120,10))\n",
    "\n",
    "    # Add a Global Average Pooling to flatten the output of the neural encoder\n",
    "    h = base_model(inputs, training=True)\n",
    "    h = GlobalAveragePooling2D()(h)\n",
    "\n",
    "    # Add the projection head layers with Relu activations\n",
    "    projection_1 = Dense(hidden_1)(h)\n",
    "    projection_1 = Activation(\"relu\")(projection_1)\n",
    "    projection_2 = Dense(hidden_2)(projection_1)\n",
    "    projection_2 = Activation(\"relu\")(projection_2)\n",
    "    projection_3 = Dense(hidden_3)(projection_2)\n",
    "\n",
    "    # Define our final model and return from function\n",
    "    simclr_model = tf.keras.models.Model(inputs, projection_3)\n",
    "\n",
    "    return simclr_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(xis, xjs, model, optimizer, criterion, temperature, batch_size):\n",
    "    \n",
    "    # Mask to remove positive examples from the batch of negative samples\n",
    "    negative_mask = helpers.get_negative_mask(batch_size)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get our latent space vectors for our two sets of augmented images.\n",
    "        zis = model(xis)\n",
    "        zjs = model(xjs)\n",
    "\n",
    "        # normalize projection feature vectors\n",
    "        zis = tf.math.l2_normalize(zis, axis=1)\n",
    "        zjs = tf.math.l2_normalize(zjs, axis=1)\n",
    "\n",
    "        # Similarity between all positive pairs\n",
    "        l_pos = losses._dot_simililarity_dim1(zis, zjs)\n",
    "        l_pos = tf.reshape(l_pos, (batch_size, 1))\n",
    "        \n",
    "        # Divide by your temperature variable or tau\n",
    "        l_pos /= temperature\n",
    "        \n",
    "        # Combine all images to create negative array \n",
    "        negatives = tf.concat([zjs, zis], axis=0)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # Compare every image vector to every other image vector \n",
    "        for positives in [zis, zjs]:\n",
    "            \n",
    "            l_neg = losses._dot_simililarity_dim2(positives, negatives)\n",
    "            \n",
    "            # Negative examples have zero label\n",
    "            labels = tf.zeros(batch_size, dtype=tf.int32)\n",
    "\n",
    "            # Mask out the positive pairs\n",
    "            l_neg = tf.boolean_mask(l_neg, negative_mask)\n",
    "                   \n",
    "            l_neg = tf.reshape(l_neg, (batch_size, -1))\n",
    "            l_neg /= temperature\n",
    "\n",
    "            logits = tf.concat([l_pos, l_neg], axis=1) \n",
    "            \n",
    "            # Cross entropy loss\n",
    "            loss += criterion(y_pred=logits, y_true=labels)\n",
    "\n",
    "        loss = loss / (2 * batch_size)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_model(name, BATCH_SIZE, epochs, architecture, temperature):\n",
    "    \n",
    "    '''\n",
    "    Main execution function used to take input flags and control overall model flow.\n",
    "    \n",
    "    name: -string Output name for model file\n",
    "    BATCH_SIZE: int- batch size to use during training - set to be large\n",
    "    epochs: int - number of passes over the data\n",
    "    architecture: - tensorflow.keras.applications model to use as neural encoder\n",
    "    temperature: float - temperature for the softmax\n",
    "    ca_flag: Boolean - specify whether training on California data or BEN data\n",
    "    '''\n",
    "    \n",
    "    # Log information\n",
    "    print(50 * \"*\")\n",
    "    print(f\"Running model: SimCLR {name}\")\n",
    "    print(50 * \"=\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(50 * \"=\")\n",
    "    print(f'Using Model Architecture: {architecture}')\n",
    "    \n",
    "    # California data has different files\n",
    "#     if ca_flag:\n",
    "#         training_filenames = f'{TFR_PATH}/train_ca_part*.tfrecord'\n",
    "#     else:\n",
    "#         training_filenames = f'{TFR_PATH}/train-part*.tfrecord'\n",
    "    training_filenames = f'{TFR_PATH}/train-part*.tfrecord'\n",
    "\n",
    "      \n",
    "    # Get the training files in batches  \n",
    "    training_data = get_training_dataset(training_filenames, BATCH_SIZE)\n",
    "\n",
    "    # Use Cross Entropy Loss\n",
    "    criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
    "                                                          reduction=tf.keras.losses.Reduction.SUM)\n",
    "    # Learning Rate Decay with stochastic gradient descent\n",
    "    decay_steps = 1000\n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=0.1, decay_steps=decay_steps)\n",
    "    optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
    "\n",
    "    # Build the model with the following hidden layer sizes\n",
    "    simclr_2 = build_simclr_model(architecture,1024, 512, 128)\n",
    "    \n",
    "    # Print Summary of model for user\n",
    "    simclr_2.summary()\n",
    "\n",
    "    # List for tracking losses by epoch\n",
    "    epoch_wise_loss = []\n",
    "    \n",
    "    # Track time spent per epoch\n",
    "    time_callback = TimeHistory()\n",
    "    \n",
    "    # Augment Class used for color distortion and Gaussian Blur\n",
    "    augment = Augment()\n",
    "    \n",
    "    # Set Other Augmentation data\n",
    "    ROTATION = 180\n",
    "    SHIFT = 0.10\n",
    "    FLIP = True\n",
    "    ZOOM = 0.20\n",
    "    JITTER = 0.0\n",
    "    BLUR = True\n",
    "    \n",
    "    # Use Keras to augment images in batches\n",
    "    datagen = image.ImageDataGenerator(\n",
    "            rotation_range=ROTATION,\n",
    "            width_shift_range=SHIFT,\n",
    "            height_shift_range=SHIFT,\n",
    "            horizontal_flip=FLIP,\n",
    "            vertical_flip=FLIP,\n",
    "            zoom_range=ZOOM,\n",
    "            preprocessing_function= augment.augfunc)\n",
    "    \n",
    "    min_loss = 1e6\n",
    "    min_loss_epoch = 0\n",
    "    \n",
    "    # Manually walk through epochs and batches\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        step_wise_loss = []\n",
    "      \n",
    "      # Loop over batches, perform augmentation and calculate poss\n",
    "        for image_batch in tqdm(training_data):\n",
    "            # Use the data generator to augment the data - DO NOT SHUFFLE - images need to stay aligned\n",
    "            a = datagen.flow(image_batch, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            b = datagen.flow(image_batch, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            # Send image arrays, simclr model, etc to our train_step function\n",
    "            loss = train_step(a[0][0], b[0][0], simclr_2, optimizer, criterion, temperature=temperature, batch_size=BATCH_SIZE)\n",
    "            step_wise_loss.append(loss)\n",
    "\n",
    "    # Append to list of loss by epoch\n",
    "    epoch_wise_loss.append(np.mean(step_wise_loss))\n",
    "\n",
    "    # Print the loss after every epoch\n",
    "    print(f\"****epoch: {epoch + 1} loss: {epoch_wise_loss[-1]:.3f}****\\n\")\n",
    "\n",
    "    # Save weights every five epochs\n",
    "    if (epoch > 0) and ((epoch+1) % 5 == 0):\n",
    "        print(f'Saving weights for epoch: {epoch+1}')\n",
    "        # Save the final model with weights\n",
    "        simclr_2.save(f'{OUTPUT_PATH}/{name}_{epoch+1}.h5')\n",
    "\n",
    "    # Store the epochwise loss and model metadata to dataframe\n",
    "    df = pd.DataFrame(epoch_wise_loss)\n",
    "    df['temperature'] = temperature\n",
    "    df['batch_size'] = BATCH_SIZE\n",
    "    df['epochs'] = epochs\n",
    "    df['h1'] = 1024\n",
    "    df['h2'] = 512\n",
    "    df['output_dim'] = 128\n",
    "    df['rotation'] = ROTATION\n",
    "    df['shift'] = SHIFT\n",
    "    df['flip'] = FLIP\n",
    "    df['zoom'] = ZOOM\n",
    "    df['jitter'] = JITTER\n",
    "    df['blur'] = BLUR\n",
    "  \n",
    "    df.to_pickle(f'{OUTPUT_PATH}/{name}.pkl')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting a dataset generator for our training data. \n",
    "# The flags affect which tfrecords files to use and how to normalize each.\n",
    "def get_training_dataset(training_filenames, batch_size):\n",
    "#     return get_batched_dataset(training_filenames, batch_size, simclr=True, ca=ca_flag)\n",
    "    return get_batched_dataset(training_filenames, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "def run_model(name, BATCH_SIZE, epochs, architecture, temperature):\n",
    "    \n",
    "    print(50 * \"*\")\n",
    "    print(f\"Running model: SimCLR {name}\")\n",
    "    print(50 * \"=\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(50 * \"=\")\n",
    "    print(f'Using Model Architecture: {architecture}')\n",
    "    \n",
    "    training_filenames = f'{TFR_PATH}/train-part*.tfrecord'\n",
    "    training_data = get_training_dataset(training_filenames, BATCH_SIZE)\n",
    "\n",
    "#     len_train_records = 9942*5\n",
    "#     steps_per_epoch = len_train_records // BATCH_SIZE\n",
    "    \n",
    "    criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
    "                                                          reduction=tf.keras.losses.Reduction.SUM)\n",
    "    decay_steps = 1000\n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=0.1, decay_steps=decay_steps)\n",
    "    optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
    "\n",
    "    simclr_2 = build_simclr_model(architecture,1024, 512, 128)\n",
    "    simclr_2.summary()\n",
    "\n",
    "    \n",
    "    epoch_wise_loss = []\n",
    "    \n",
    "    time_callback = TimeHistory()\n",
    "    augment = Augment()\n",
    "    \n",
    "    ROTATION = 180\n",
    "    SHIFT = 0.10\n",
    "    FLIP = True\n",
    "    ZOOM = 0.20\n",
    "    JITTER = True\n",
    "    BLUR = True\n",
    "    \n",
    "    datagen = image.ImageDataGenerator(\n",
    "            rotation_range=ROTATION,\n",
    "            width_shift_range=SHIFT,\n",
    "            height_shift_range=SHIFT,\n",
    "            horizontal_flip=FLIP,\n",
    "            vertical_flip=FLIP,\n",
    "            zoom_range=ZOOM,\n",
    "            preprocessing_function= augment.augfunc)\n",
    "    \n",
    "    min_loss = 1e6\n",
    "    min_loss_epoch = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        step_wise_loss = []\n",
    "        for image_batch in tqdm(training_data):\n",
    "            a = datagen.flow(image_batch, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            b = datagen.flow(image_batch, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            loss = train_step(a[0][0], b[0][0], simclr_2, optimizer, criterion, temperature=0.1, batch_size=BATCH_SIZE)\n",
    "            step_wise_loss.append(loss)\n",
    "            \n",
    "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
    "        \n",
    "    # Print the loss after every epoch\n",
    "    print(f\"****epoch: {epoch + 1} loss: {epoch_wise_loss[-1]:.3f}****\\n\")\n",
    "        \n",
    "      # Save best weights\n",
    "    if epoch_wise_loss[-1] < min_loss:\n",
    "        # Save the final model with weights\n",
    "        simclr_2.save(f'{OUTPUT_PATH}/{name}.h5')\n",
    "        min_loss_epoch = epoch+1\n",
    "  \n",
    "    # Store the epochwise loss and model metadata to dataframe\n",
    "    df = pd.DataFrame(epoch_wise_loss)\n",
    "    df['temperature'] = temperature\n",
    "    df['batch_size'] = BATCH_SIZE\n",
    "    df['epochs'] = epochs\n",
    "    df['h1'] = 1024\n",
    "    df['h2'] = 512\n",
    "    df['output_dim'] = 128\n",
    "    df['rotation'] = ROTATION\n",
    "    df['shift'] = ROTATION\n",
    "    df['flip'] = ROTATION\n",
    "    df['zoom'] = ROTATION\n",
    "    df['jitter'] = ROTATION\n",
    "    df['blur'] = ROTATION\n",
    "    df['best_epoch'] = min_loss_epoch\n",
    "  \n",
    "    df.to_pickle(f'{OUTPUT_PATH}/{name}.pkl')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Running model: SimCLR simclr1\n",
      "==================================================\n",
      "Batch Size: 32\n",
      "==================================================\n",
      "Using Model Architecture: <function ResNet50 at 0x7fa9ddf89ea0>\n",
      "Filenames: /workspace/app/data/processed/train-part*.tfrecord\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Length for attr 'output_shapes' of 0 must be at least minimum 1\n\t; NodeDef: {{node ParallelMapDatasetV2}}; Op<name=ParallelMapDatasetV2; signature=input_dataset:variant, other_arguments:, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=deterministic:string,default=\"default\"; attr=preserve_cardinality:bool,default=false> [Op:ParallelMapDatasetV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-19c5dc584526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0marchitecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           temperature=0.1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-064f94a0af76>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(name, BATCH_SIZE, epochs, architecture, temperature)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtraining_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{TFR_PATH}/train-part*.tfrecord'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     len_train_records = 9942*5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-02f514318988>\u001b[0m in \u001b[0;36mget_training_dataset\u001b[0;34m(training_filenames, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     return get_batched_dataset(training_filenames, batch_size, simclr=True, ca=ca_flag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-c76ad5144e43>\u001b[0m in \u001b[0;36mget_batched_dataset\u001b[0;34m(filenames, batch_size, augment)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#.repeat()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_tfrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# drop_remainder will be needed on TPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4100\u001b[0m         \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m         \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   4103\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallelMapDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mparallel_map_dataset_v2\u001b[0;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, name)\u001b[0m\n\u001b[1;32m   5090\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5091\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5092\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5093\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5094\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Length for attr 'output_shapes' of 0 must be at least minimum 1\n\t; NodeDef: {{node ParallelMapDatasetV2}}; Op<name=ParallelMapDatasetV2; signature=input_dataset:variant, other_arguments:, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=deterministic:string,default=\"default\"; attr=preserve_cardinality:bool,default=false> [Op:ParallelMapDatasetV2]"
     ]
    }
   ],
   "source": [
    "run_model('simclr1',\n",
    "          BATCH_SIZE=32,\n",
    "          epochs=5,\n",
    "          architecture=ResNet50,\n",
    "          temperature=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In main function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [-a {ResNet50,ResNet101V2,Xception,InceptionV3}]\n",
      "                             [-o OUTPUT] [-b BATCH_SIZE] [-e EPOCHS]\n",
      "                             [-t TEMPERATURE] [-c CALIFORNIA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-959b62a8-05b6-4919-a0e3-0a01da3c04b9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('In main function')\n",
    "    parser = argparse.ArgumentParser(description='Script for running different supervised classifiers')\n",
    "    parser.add_argument('-a', '--arch', choices=['ResNet50', 'ResNet101V2', 'Xception', 'InceptionV3'],\n",
    "                        help='Class of Model Architecture to use for classification')\n",
    "    parser.add_argument('-o', '--output', type=str,\n",
    "                        help='Output File Prefix for model file and dataframe')\n",
    "    parser.add_argument('-b', '--BATCH_SIZE', default=32, type=int,\n",
    "                       help=\"batch size to use during training and validation\")\n",
    "    parser.add_argument('-e', '--EPOCHS', default=50, type=int,\n",
    "                        help=\"number of epochs to run\")\n",
    "    parser.add_argument('-t', '--TEMPERATURE', default=0.1, type=float,\n",
    "                        help=\"temperature to use during contrastive loss calculation\")\n",
    "    parser.add_argument('-c', '--CALIFORNIA', default='False', type=str,\n",
    "                        help=\"are you running with california data\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    arch_dict = {'ResNet50': ResNet50,\n",
    "                 'ResNet101V2':ResNet101V2,\n",
    "                 'Xception':Xception,\n",
    "                 'InceptionV3':InceptionV3}\n",
    "    ca_flag_dict = {'True':True, 'False':False}\n",
    "        \n",
    "    run_model(args.output,\n",
    "                  BATCH_SIZE=args.BATCH_SIZE,\n",
    "                  epochs=args.EPOCHS,\n",
    "                  architecture=arch_dict[args.arch],\n",
    "                  temperature=args.TEMPERATURE,\n",
    "                  ca_flag=ca_flag_dict[args.CALIFORNIA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
