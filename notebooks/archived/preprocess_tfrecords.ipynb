{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z0HiNpYt6zD"
   },
   "source": [
    "# Big Earth Net Preprocessing\n",
    "## Irrigation Capstone Fall 2020\n",
    "### TP Goter\n",
    "\n",
    "This notebook is used to preprocess the GeoTiff files that contain the Sentinel-2 MSI data comprising the BigEarthNet dataset into TFRecords files. It is based on the preprocessing scripts from the BigEarthNet repo, but has been updated to work in Colaboratory with Python3.7+ and TensorFlow 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4841,
     "status": "ok",
     "timestamp": 1601156548878,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "b0r4VAo9eRWa",
    "outputId": "0d884a87-7e43-470a-98f9-0312431f02ba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4836,
     "status": "ok",
     "timestamp": 1601156548880,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "i8AXp5QRfCMR",
    "outputId": "58c67cd6-4e0a-452b-ba6b-2414f9a44ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.5\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFjjrUFAucPm"
   },
   "source": [
    "## Mount Google Drive and Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8nvKWoMlfGZ4"
   },
   "outputs": [],
   "source": [
    "# base_path = '/content/gdrive/My Drive/Capstone Project'\n",
    "big_earth_path ='/workspace/app/data/raw/BigEarthNet-v1.0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUcdgz7bugBq"
   },
   "source": [
    "## Create Symbolic Link(s)\n",
    "Set up a symbolic link to allow for easy Python module imports. Then check to make sure the link works (it is a Unix link so check from shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 3169,
     "status": "ok",
     "timestamp": 1601121478276,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "lnsWI7TngGOd",
    "outputId": "53e74cb7-9a99-45d0-fc76-c578d06e763f"
   },
   "outputs": [],
   "source": [
    "!ln -s '/workspace/app/data/raw/bigearthnet-models/' bemodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 3163,
     "status": "ok",
     "timestamp": 1601121478277,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "GGLMTMT_gyvz",
    "outputId": "9cd87b89-0dfc-4dd8-c201-9a89e6ae583a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE    __pycache__\t       prep_splits.py  tensorflow_utils.py\r\n",
      "README.md  label_indices.json  splits\r\n"
     ]
    }
   ],
   "source": [
    "!ls bemodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tIho5IV_giss"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK0uOlk8utUU"
   },
   "source": [
    "## Process All of the BigEarthNet data\n",
    "This simple script will loop over all of the subfolders in the BigEarthNet-v1.0 folder. Currently this folder does not contain the entirety of the BigEarthNet Dataset. Due to this issue, the original scripting was modified to run through the train, test, val sets and only process files if they exist. The previous script simply aborted if a file was listed in the train.csv file and was not in the directory.\n",
    "\n",
    "### Note: This processing takes a really long time. \n",
    "We need to determine if there is a better way to get this data ready for ingestion into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "11N4a4EE-0HGNHlfvZEA3G8x3YzUjEkgn"
    },
    "id": "njMMPbVdfW_f",
    "outputId": "b9d26719-73d9-4a29-b160-76b70fae086e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: TFRecord writer is not able to write files\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/workspace/app/notebooks/archived/bemodels/tensorflow_utils.py\u001b[0m in \u001b[0;36mprep_tf_record_files\u001b[0;34m(root_folder, out_folder, split_names, patch_names_list, label_indices, GDAL_EXISTED, RASTERIO_EXISTED)\u001b[0m\n\u001b[1;32m     95\u001b[0m             writer_list.append(\n\u001b[0;32m---> 96\u001b[0;31m                     tf.compat.v1.python_io.TFRecordWriter(os.path.join(\n\u001b[0m\u001b[1;32m     97\u001b[0m                         out_folder, split_name + '.tfrecord'))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'python_io'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f51869773fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msplit_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_names_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     label_indices, False, True)\n\u001b[0m",
      "\u001b[0;32m/workspace/app/notebooks/archived/bemodels/tensorflow_utils.py\u001b[0m in \u001b[0;36mprep_tf_record_files\u001b[0;34m(root_folder, out_folder, split_names, patch_names_list, label_indices, GDAL_EXISTED, RASTERIO_EXISTED)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR: TFRecord writer is not able to write files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msplit_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_names_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from bemodels import tensorflow_utils\n",
    "\n",
    "with open('/workspace/app/data/raw/bigearthnet-models/label_indices.json', 'rb') as f:\n",
    "    label_indices = json.load(f)\n",
    "\n",
    "root_folder = big_earth_path\n",
    "out_folder = '/workspace/app/data/processed/tfrecords'\n",
    "splits = glob(f'/workspace/app/data/raw/bigearthnet-models/splits/train.csv')\n",
    "\n",
    "# Checks the existence of patch folders and populate the list of patch folder paths\n",
    "folder_path_list = []\n",
    "if not os.path.exists(root_folder):\n",
    "    print('ERROR: folder', root_folder, 'does not exist')\n",
    "\n",
    "try:\n",
    "    patch_names_list = []\n",
    "    split_names = []\n",
    "    for csv_file in splits:\n",
    "        patch_names_list.append([])\n",
    "        split_names.append(os.path.basename(csv_file).split('.')[0])\n",
    "        with open(csv_file, 'r') as fp:\n",
    "            csv_reader = csv.reader(fp, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                patch_names_list[-1].append(row[0].strip())    \n",
    "except:\n",
    "    print('ERROR: some csv files either do not exist or have been corrupted')\n",
    "\n",
    "tensorflow_utils.prep_tf_record_files(\n",
    "    root_folder, out_folder, \n",
    "    split_names, patch_names_list, \n",
    "    label_indices, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_labels': {'Continuous urban fabric': 0,\n",
       "  'Discontinuous urban fabric': 1,\n",
       "  'Industrial or commercial units': 2,\n",
       "  'Road and rail networks and associated land': 3,\n",
       "  'Port areas': 4,\n",
       "  'Airports': 5,\n",
       "  'Mineral extraction sites': 6,\n",
       "  'Dump sites': 7,\n",
       "  'Construction sites': 8,\n",
       "  'Green urban areas': 9,\n",
       "  'Sport and leisure facilities': 10,\n",
       "  'Non-irrigated arable land': 11,\n",
       "  'Permanently irrigated land': 12,\n",
       "  'Rice fields': 13,\n",
       "  'Vineyards': 14,\n",
       "  'Fruit trees and berry plantations': 15,\n",
       "  'Olive groves': 16,\n",
       "  'Pastures': 17,\n",
       "  'Annual crops associated with permanent crops': 18,\n",
       "  'Complex cultivation patterns': 19,\n",
       "  'Land principally occupied by agriculture, with significant areas of natural vegetation': 20,\n",
       "  'Agro-forestry areas': 21,\n",
       "  'Broad-leaved forest': 22,\n",
       "  'Coniferous forest': 23,\n",
       "  'Mixed forest': 24,\n",
       "  'Natural grassland': 25,\n",
       "  'Moors and heathland': 26,\n",
       "  'Sclerophyllous vegetation': 27,\n",
       "  'Transitional woodland/shrub': 28,\n",
       "  'Beaches, dunes, sands': 29,\n",
       "  'Bare rock': 30,\n",
       "  'Sparsely vegetated areas': 31,\n",
       "  'Burnt areas': 32,\n",
       "  'Inland marshes': 33,\n",
       "  'Peatbogs': 34,\n",
       "  'Salt marshes': 35,\n",
       "  'Salines': 36,\n",
       "  'Intertidal flats': 37,\n",
       "  'Water courses': 38,\n",
       "  'Water bodies': 39,\n",
       "  'Coastal lagoons': 40,\n",
       "  'Estuaries': 41,\n",
       "  'Sea and ocean': 42}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3o4Ya6iMz66"
   },
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"./tfrecords/full_test.tfrecord\")\n",
    "\n",
    "shards = 20\n",
    "\n",
    "for i in range(shards):\n",
    "    writer = tf.data.experimental.TFRecordWriter(f\"./tfrecords/test-part-{i}.tfrecord\")\n",
    "    writer.write(raw_dataset.shard(shards, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"./tfrecords/full_train.tfrecord\")\n",
    "\n",
    "shards = 50\n",
    "\n",
    "for i in range(shards):\n",
    "    writer = tf.data.experimental.TFRecordWriter(f\"./tfrecords/train-part-{i}.tfrecord\")\n",
    "    writer.write(raw_dataset.shard(shards, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"./tfrecords/full_val.tfrecord\")\n",
    "\n",
    "shards = 20\n",
    "\n",
    "for i in range(shards):\n",
    "    writer = tf.data.experimental.TFRecordWriter(f\"./tfrecords/val-part-{i}.tfrecord\")\n",
    "    writer.write(raw_dataset.shard(shards, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM/8/SHpGq20T8v/exkRAUj",
   "collapsed_sections": [],
   "name": "preprocess_tfrecords.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
